{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5faf256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yf\n",
    "import seaborn as sns\n",
    "yf.pdr_override()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "056961ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Algorithm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Regularization\n",
    "from sklearn.linear_model import Lasso #because we are selecting features.\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeRegressor #worst performer because there is no pruning?\n",
    "\n",
    "# ENSEMBLE\n",
    "\n",
    "## Bagging (bootstrap aggregation) #likely to overfit too because its underlying uses decision tree \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "## Boosting\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "# for cross-validation\n",
    "from sklearn.model_selection import cross_val_score #perf, mean, variance and std error\n",
    "from sklearn.model_selection import KFold # we can tune it as hyperparameter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# for assessment\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# for Feature Selection\n",
    "from sklearn.feature_selection import chi2, f_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "#import dependency for time series modelling\n",
    "\n",
    "import statsmodels.tsa.arima.model as stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from pandas.plotting import scatter_matrix #plot of correlation matrix and kernel density plotting\n",
    "\n",
    "# for Pre-processing (Feature Engineering)\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20d645e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backtest:\n",
    "    def __init__(self,data, base_, tradingexp_):\n",
    "        self.data=data\n",
    "        self.base=base_\n",
    "        self.tradingexp = tradingexp_\n",
    "        ## Write any processing that needs to be done on the data\n",
    "        self.data['Buy_Sell']= self.data['Position'] - self.data['Position'].shift(1)\n",
    "        self.data['log_return']=np.log(self.data['Adj Close']/self.data['Adj Close'].shift(1))\n",
    "        self.data['Strategy_return']=self.data['Position'].shift(1)*self.data['log_return']\n",
    "        self.data['Expense']=np.where(abs(self.data['Buy_Sell'])> 0, self.tradingexp, 0)\n",
    "        self.data['Capital']= self.base*self.data['Strategy_return'].cumsum().apply(np.exp)\n",
    "        self.data['Adj Capital'] = self.base*self.data['Strategy_return'].cumsum().apply(np.exp) - self.data['Expense'].shift(1).cumsum()\n",
    "        self.data['Adj return'] = np.log(self.data['Adj Capital']/self.data['Adj Capital'].shift(1))\n",
    "        self.data['drawdown']=self.data['Adj return'].cumsum() - self.data['Adj return'].cumsum().cummax()\n",
    "\n",
    "                \n",
    "    def plot_backtest_buy_sell(self): \n",
    "        ax=\\\n",
    "        (\n",
    "            self.data[['Adj Close',\n",
    "                       'Position']]\n",
    "            .plot(figsize=(18,8),\n",
    "                  secondary_y=[\"Position\"],\n",
    "                  style=[\"red\",\"b--\"],\n",
    "                  alpha=0.5\n",
    "                 )\n",
    "        )\n",
    "\n",
    "        (\n",
    "            ax.legend(loc=\"upper center\"\n",
    "                      ,shadow=True\n",
    "                      ,fancybox=True\n",
    "                      ,bbox_to_anchor=(0.55,1.10)\n",
    "                      ,ncol=4\n",
    "                     )\n",
    "        )\n",
    "\n",
    "        bx=\\\n",
    "        (\n",
    "            self.data[self.data['Buy_Sell']>0]['Adj Close']\n",
    "            .plot(style=\"g^\",\n",
    "                  markersize=12,\n",
    "                  label='Buy')\n",
    "        )\n",
    "\n",
    "        bx.legend()\n",
    "\n",
    "        cx=\\\n",
    "        (\n",
    "            self.data[self.data['Buy_Sell']<0]['Adj Close']\n",
    "            .plot(style=\"rv\",\n",
    "                  markersize=12,\n",
    "                  label=\"Sell\")\n",
    "        )\n",
    "        \n",
    "        cx.legend()\n",
    "        plt.title(f\"Backtest Buy Sell Signals\")\n",
    "        plt.show()\n",
    "      \n",
    "    def calculate_cumm_return(self):\n",
    "        res=100*(np.exp(self.data['Adj return'].sum()) -1)\n",
    "        print(f\"Cummulative return is: {res:.2f}% with final Account balance: ${self.data['Adj Capital'].iloc[-1]}\")\n",
    "\n",
    "    def calculate_max_drawdown(self):\n",
    "        res=100* (np.exp(self.data['drawdown'].min()) - 1)\n",
    "        print(f\"Max Drawdown: {res:.2f}%\")\n",
    "    \n",
    "    def calculate_max_drawdown_duration(self):\n",
    "        periods =\\\n",
    "        self.data[self.data['drawdown'] == 0].index[ 1 :   ].to_pydatetime() \\\n",
    "        - self.data[self.data['drawdown'] == 0].index[   : -1].to_pydatetime()\n",
    "        print(f\"Max Drawdown Duration: {periods.max()}\")\n",
    "\n",
    "    def calculate_return_byyear(self):\n",
    "        grpByYear=self.data.groupby(self.data.index.year)\n",
    "        return grpByYear['Adj return'].sum().apply(np.exp) -1\n",
    "\n",
    "    def calculate_sharpe_ratio(self):\n",
    "        res = np.sqrt(252) * (self.data['Adj return'].dropna().apply(np.exp).add(-1).mean()) / (self.data['Adj return'].dropna().apply(np.exp).add(-1).std())\n",
    "        print(f\"Sharpe Ratio: {res:.3f}\")\n",
    "\n",
    "    def calculate_cagr(self):\n",
    "        days =(self.data.index[-1] - self.data.index[0]).days\n",
    "        CAGR =100*(((np.exp(self.data['Adj return'].sum()))**(365.0/days)) - 1)\n",
    "        print(f\"Strategy CAGR is: {CAGR:.2f}%\")\n",
    "        \n",
    "    def plot_backtest_returns(self):\n",
    "        ax =\\\n",
    "        (\n",
    "            self.data[[\"log_return\", \"Adj return\"]]\n",
    "            .dropna()\n",
    "            .cumsum()\n",
    "            .apply(np.exp)\n",
    "            .add(-1)\n",
    "            .plot(figsize = [18, 7])\n",
    "        )\n",
    "        \n",
    "        ax.set_title(f\"Back Test Strategy vs Asset Return\")\n",
    "        ax.legend([\"Asset Cumm Return\",\"Strategy Cumm Return (Adj)\"])\n",
    "        bx =\\\n",
    "        (\n",
    "            self.data['Adj return']\n",
    "            .cumsum()\n",
    "            .cummax()\n",
    "            .apply(np.exp)\n",
    "            .add(-1)\n",
    "            .plot(ax=ax)\n",
    "        )\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_all_stats(self):\n",
    "        self.calculate_cumm_return()\n",
    "        self.calculate_cagr()\n",
    "        self.calculate_max_drawdown()\n",
    "        self.calculate_sharpe_ratio()\n",
    "        self.plot_backtest_buy_sell()\n",
    "        self.plot_backtest_returns()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06b8d92",
   "metadata": {},
   "source": [
    "# FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee9eefad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "capital = 1e5\n",
    "start_date = dt.datetime(2004,11,1)\n",
    "end_date = dt.datetime(2023,11,1)\n",
    "\n",
    "spy = pdr.get_data_yahoo(\"SPY\", start = start_date, end = end_date)\n",
    "Y = np.log(spy[\"Adj Close\"]).diff(1).shift(-1)\n",
    "Y.name = \"Y_pred\"\n",
    "\n",
    "tnx_ticker = \"^TNX\"\n",
    "\n",
    "tnx_data = yf.download(tnx_ticker, start=start_date, end=end_date)\n",
    "\n",
    "X0 = np.log(tnx_data[\"Adj Close\"])\n",
    "X0 = X0.ffill()\n",
    "X0.name = \"10years futures\"\n",
    "\n",
    "vix_ticker = \"^VIX\"\n",
    "\n",
    "vix = yf.download(vix_ticker, start=start_date, end=end_date)\n",
    "\n",
    "X0_1 = np.log(vix[\"Adj Close\"])\n",
    "X0_1 = X0_1.ffill()\n",
    "X0_1.name = \"vix\"\n",
    "\n",
    "X1 = np.log(spy[\"Volume\"])\n",
    "X2 =\\\n",
    "(pd.concat([Y.\n",
    "            diff(i) \n",
    "            for i in [3,6,12]], \n",
    "                   axis = 1\n",
    "          )\n",
    " #.dropna()\n",
    ")\n",
    "X2.columns = [\"SPY_3\", \"SPY_6\", \"SPY_12\"]\n",
    "\n",
    "X3 =\\\n",
    "(\n",
    "    pd.concat([X1.shift(i)\n",
    "               #.diff(i) \n",
    "               for i in [3,6,12]],\n",
    "                      axis =1\n",
    "             )\n",
    ")\n",
    "X3.columns = [\"Volume_3\", \"Volume_6\", \"Volume_12\"]\n",
    "\n",
    "X =\\\n",
    "(\n",
    "        pd.concat([X0, X0_1, X1, X2, X3],\n",
    "                 axis = 1)\n",
    ")\n",
    "\n",
    "#no trading signal for the first 12 days\n",
    "X_traintest = X.iloc[12:]\n",
    "Y_traintest = Y.iloc[12:]\n",
    "\n",
    "X_traintest = X_traintest.ffill()\n",
    "\n",
    "\n",
    "#interpreting Y returns in binary signal\n",
    "Y_traintest_binary = (Y_traintest > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29df00de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10years futures</th>\n",
       "      <th>vix</th>\n",
       "      <th>Volume</th>\n",
       "      <th>SPY_3</th>\n",
       "      <th>SPY_6</th>\n",
       "      <th>SPY_12</th>\n",
       "      <th>Volume_3</th>\n",
       "      <th>Volume_6</th>\n",
       "      <th>Volume_12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-11-17</th>\n",
       "      <td>1.421662</td>\n",
       "      <td>2.580974</td>\n",
       "      <td>17.813601</td>\n",
       "      <td>-0.001105</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>17.833401</td>\n",
       "      <td>17.614546</td>\n",
       "      <td>17.418857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-11-18</th>\n",
       "      <td>1.415125</td>\n",
       "      <td>2.563410</td>\n",
       "      <td>17.276683</td>\n",
       "      <td>-0.003995</td>\n",
       "      <td>-0.018759</td>\n",
       "      <td>-0.023694</td>\n",
       "      <td>17.379334</td>\n",
       "      <td>17.628054</td>\n",
       "      <td>17.844605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-11-19</th>\n",
       "      <td>1.434132</td>\n",
       "      <td>2.602690</td>\n",
       "      <td>17.809602</td>\n",
       "      <td>-0.001163</td>\n",
       "      <td>-0.003102</td>\n",
       "      <td>-0.008804</td>\n",
       "      <td>17.505107</td>\n",
       "      <td>17.449490</td>\n",
       "      <td>18.158799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-11-22</th>\n",
       "      <td>1.426716</td>\n",
       "      <td>2.562639</td>\n",
       "      <td>17.441456</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>-0.000929</td>\n",
       "      <td>-0.004719</td>\n",
       "      <td>17.813601</td>\n",
       "      <td>17.833401</td>\n",
       "      <td>17.829193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-11-23</th>\n",
       "      <td>1.431268</td>\n",
       "      <td>2.539237</td>\n",
       "      <td>17.552437</td>\n",
       "      <td>0.013546</td>\n",
       "      <td>0.009551</td>\n",
       "      <td>0.003817</td>\n",
       "      <td>17.276683</td>\n",
       "      <td>17.379334</td>\n",
       "      <td>17.963194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-25</th>\n",
       "      <td>1.599993</td>\n",
       "      <td>3.005187</td>\n",
       "      <td>18.361177</td>\n",
       "      <td>-0.010312</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>-0.017238</td>\n",
       "      <td>18.634548</td>\n",
       "      <td>18.137319</td>\n",
       "      <td>18.202206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-26</th>\n",
       "      <td>1.577947</td>\n",
       "      <td>3.029167</td>\n",
       "      <td>18.561805</td>\n",
       "      <td>-0.012054</td>\n",
       "      <td>0.004282</td>\n",
       "      <td>-0.008631</td>\n",
       "      <td>18.337681</td>\n",
       "      <td>18.354111</td>\n",
       "      <td>18.179975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-27</th>\n",
       "      <td>1.577947</td>\n",
       "      <td>3.057298</td>\n",
       "      <td>18.491770</td>\n",
       "      <td>0.026341</td>\n",
       "      <td>0.024249</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>18.179427</td>\n",
       "      <td>18.613967</td>\n",
       "      <td>17.949904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-30</th>\n",
       "      <td>1.584120</td>\n",
       "      <td>2.983153</td>\n",
       "      <td>18.276380</td>\n",
       "      <td>0.018308</td>\n",
       "      <td>0.007995</td>\n",
       "      <td>0.011254</td>\n",
       "      <td>18.361177</td>\n",
       "      <td>18.634548</td>\n",
       "      <td>18.211862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-31</th>\n",
       "      <td>1.584120</td>\n",
       "      <td>2.898119</td>\n",
       "      <td>18.193343</td>\n",
       "      <td>0.018308</td>\n",
       "      <td>0.007995</td>\n",
       "      <td>0.011254</td>\n",
       "      <td>18.561805</td>\n",
       "      <td>18.337681</td>\n",
       "      <td>18.370893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4771 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            10years futures       vix     Volume     SPY_3     SPY_6  \\\n",
       "Date                                                                   \n",
       "2004-11-17         1.421662  2.580974  17.813601 -0.001105  0.000578   \n",
       "2004-11-18         1.415125  2.563410  17.276683 -0.003995 -0.018759   \n",
       "2004-11-19         1.434132  2.602690  17.809602 -0.001163 -0.003102   \n",
       "2004-11-22         1.426716  2.562639  17.441456  0.000176 -0.000929   \n",
       "2004-11-23         1.431268  2.539237  17.552437  0.013546  0.009551   \n",
       "...                     ...       ...        ...       ...       ...   \n",
       "2023-10-25         1.599993  3.005187  18.361177 -0.010312  0.001368   \n",
       "2023-10-26         1.577947  3.029167  18.561805 -0.012054  0.004282   \n",
       "2023-10-27         1.577947  3.057298  18.491770  0.026341  0.024249   \n",
       "2023-10-30         1.584120  2.983153  18.276380  0.018308  0.007995   \n",
       "2023-10-31         1.584120  2.898119  18.193343  0.018308  0.007995   \n",
       "\n",
       "              SPY_12   Volume_3   Volume_6  Volume_12  \n",
       "Date                                                   \n",
       "2004-11-17  0.000997  17.833401  17.614546  17.418857  \n",
       "2004-11-18 -0.023694  17.379334  17.628054  17.844605  \n",
       "2004-11-19 -0.008804  17.505107  17.449490  18.158799  \n",
       "2004-11-22 -0.004719  17.813601  17.833401  17.829193  \n",
       "2004-11-23  0.003817  17.276683  17.379334  17.963194  \n",
       "...              ...        ...        ...        ...  \n",
       "2023-10-25 -0.017238  18.634548  18.137319  18.202206  \n",
       "2023-10-26 -0.008631  18.337681  18.354111  18.179975  \n",
       "2023-10-27  0.018000  18.179427  18.613967  17.949904  \n",
       "2023-10-30  0.011254  18.361177  18.634548  18.211862  \n",
       "2023-10-31  0.011254  18.561805  18.337681  18.370893  \n",
       "\n",
       "[4771 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_traintest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c42dec03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10years futures</th>\n",
       "      <th>vix</th>\n",
       "      <th>Volume</th>\n",
       "      <th>SPY_3</th>\n",
       "      <th>SPY_6</th>\n",
       "      <th>SPY_12</th>\n",
       "      <th>Volume_3</th>\n",
       "      <th>Volume_6</th>\n",
       "      <th>Volume_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4771.000000</td>\n",
       "      <td>4771.000000</td>\n",
       "      <td>4771.000000</td>\n",
       "      <td>4771.000000</td>\n",
       "      <td>4771.000000</td>\n",
       "      <td>4771.000000</td>\n",
       "      <td>4771.000000</td>\n",
       "      <td>4771.000000</td>\n",
       "      <td>4771.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.949562</td>\n",
       "      <td>2.884216</td>\n",
       "      <td>18.485200</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>18.484730</td>\n",
       "      <td>18.484225</td>\n",
       "      <td>18.483457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.449800</td>\n",
       "      <td>0.374347</td>\n",
       "      <td>0.594471</td>\n",
       "      <td>0.017087</td>\n",
       "      <td>0.017530</td>\n",
       "      <td>0.017018</td>\n",
       "      <td>0.594907</td>\n",
       "      <td>0.595339</td>\n",
       "      <td>0.595927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.695149</td>\n",
       "      <td>2.212660</td>\n",
       "      <td>16.541401</td>\n",
       "      <td>-0.133988</td>\n",
       "      <td>-0.165888</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>16.541401</td>\n",
       "      <td>16.541401</td>\n",
       "      <td>16.541401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.676255</td>\n",
       "      <td>2.590767</td>\n",
       "      <td>18.038105</td>\n",
       "      <td>-0.007520</td>\n",
       "      <td>-0.007547</td>\n",
       "      <td>-0.007762</td>\n",
       "      <td>18.036886</td>\n",
       "      <td>18.035614</td>\n",
       "      <td>18.033281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.982453</td>\n",
       "      <td>2.826722</td>\n",
       "      <td>18.408187</td>\n",
       "      <td>-0.000337</td>\n",
       "      <td>-0.000367</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>18.407938</td>\n",
       "      <td>18.407802</td>\n",
       "      <td>18.405829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.307522</td>\n",
       "      <td>3.115513</td>\n",
       "      <td>18.886602</td>\n",
       "      <td>0.007142</td>\n",
       "      <td>0.007140</td>\n",
       "      <td>0.007184</td>\n",
       "      <td>18.886602</td>\n",
       "      <td>18.886602</td>\n",
       "      <td>18.886602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.657847</td>\n",
       "      <td>4.415099</td>\n",
       "      <td>20.585183</td>\n",
       "      <td>0.161981</td>\n",
       "      <td>0.202618</td>\n",
       "      <td>0.135072</td>\n",
       "      <td>20.585183</td>\n",
       "      <td>20.585183</td>\n",
       "      <td>20.585183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       10years futures          vix       Volume        SPY_3        SPY_6  \\\n",
       "count      4771.000000  4771.000000  4771.000000  4771.000000  4771.000000   \n",
       "mean          0.949562     2.884216    18.485200     0.000006    -0.000003   \n",
       "std           0.449800     0.374347     0.594471     0.017087     0.017530   \n",
       "min          -0.695149     2.212660    16.541401    -0.133988    -0.165888   \n",
       "25%           0.676255     2.590767    18.038105    -0.007520    -0.007547   \n",
       "50%           0.982453     2.826722    18.408187    -0.000337    -0.000367   \n",
       "75%           1.307522     3.115513    18.886602     0.007142     0.007140   \n",
       "max           1.657847     4.415099    20.585183     0.161981     0.202618   \n",
       "\n",
       "            SPY_12     Volume_3     Volume_6    Volume_12  \n",
       "count  4771.000000  4771.000000  4771.000000  4771.000000  \n",
       "mean     -0.000014    18.484730    18.484225    18.483457  \n",
       "std       0.017018     0.594907     0.595339     0.595927  \n",
       "min      -0.142857    16.541401    16.541401    16.541401  \n",
       "25%      -0.007762    18.036886    18.035614    18.033281  \n",
       "50%      -0.000343    18.407938    18.407802    18.405829  \n",
       "75%       0.007184    18.886602    18.886602    18.886602  \n",
       "max       0.135072    20.585183    20.585183    20.585183  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_traintest.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b060cad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2004-11-17    0.001348\n",
       "2004-11-18   -0.011179\n",
       "2004-11-19    0.004758\n",
       "2004-11-22    0.001525\n",
       "2004-11-23    0.002367\n",
       "                ...   \n",
       "2023-10-25   -0.012047\n",
       "2023-10-26   -0.004543\n",
       "2023-10-27    0.011885\n",
       "2023-10-30    0.006261\n",
       "2023-10-31         NaN\n",
       "Name: Y_pred, Length: 4771, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_traintest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15e94946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10years futures    False\n",
       "vix                False\n",
       "Volume             False\n",
       "SPY_3              False\n",
       "SPY_6              False\n",
       "SPY_12             False\n",
       "Volume_3           False\n",
       "Volume_6           False\n",
       "Volume_12          False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_traintest.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7147c938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2004-11-17   -0.011179\n",
       "2004-11-18    0.004758\n",
       "2004-11-19    0.001525\n",
       "2004-11-22    0.002367\n",
       "2004-11-23   -0.000760\n",
       "                ...   \n",
       "2023-10-25   -0.004543\n",
       "2023-10-26    0.011885\n",
       "2023-10-27    0.006261\n",
       "2023-10-30         NaN\n",
       "2023-10-31         NaN\n",
       "Name: Y_pred, Length: 4771, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_traintest.shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4350830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineering more features\n",
    "# Uses F-statistics to determine model significance\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "\n",
    "index_ = Y_traintest.shift(-1).dropna().index \n",
    "\n",
    "X_poly = poly.fit_transform(X_traintest.loc[index_])\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "#(R-squared / (1 - R-squared)) * ((n - k - 1) / k)\n",
    "\n",
    "selector = SelectKBest(score_func=f_regression, k=10) #marginal improvement from when k = 8. big improvement from k = 5\n",
    "\n",
    "#we are shifting the Y values because we need to train the model for a 1 day look ahead\n",
    "X_selected = selector.fit_transform(X_poly, Y_traintest.shift(-1).loc[index_]) #Y_traintest_binary\n",
    "\n",
    "X_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219e80ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the features name used. Volume could be a cross-product or of a higher power\n",
    "\n",
    "X_columns = selector.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b530bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9ab48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected_df = pd.DataFrame(X_selected, columns = X_columns, index = X_traintest.iloc[:-2].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09391a8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_selected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efabdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import Ridge\n",
    "#from sklearn.linear_model import Lasso\n",
    "\n",
    "#between 0 to 1 where 0 is Ridge and 1 is Lasso\n",
    "penalty_ = 0.0\n",
    "\n",
    "#linear_regression2 = LinearRegression()\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=penalty_)\n",
    "#ridge_model = Ridge(alpha=1.0)\n",
    "index_ = X_selected_df.index\n",
    "elastic_net.fit(X_selected_df, Y_traintest.shift(-1).loc[index_])\n",
    "print(\"intercept is {:.3f} and coefficients are {}\".format(elastic_net.intercept_, elastic_net.coef_))\n",
    "\n",
    "EN_pred_train2 = elastic_net.predict(X_selected_df)\n",
    "print(EN_pred_train2)\n",
    "\n",
    "#continuous predictions are turned into binary signal or 1 and 0 \n",
    "\n",
    "Y_pred_binary2 = (EN_pred_train2 > 0.0).astype(int)\n",
    "Y_pred_binary2\n",
    "\n",
    "logreg_sk2 = LogisticRegression(penalty='elasticnet', l1_ratio=penalty_, solver = \"saga\")\n",
    "logreg_sk2.fit(X_selected_df, Y_pred_binary2)\n",
    "print(\"intercept is {:.3f} and coefficients are {}\".format(logreg_sk2.intercept_[0], logreg_sk2.coef_[0]))\n",
    "\n",
    "Y_pred_logistic2 = logreg_sk2.predict(X_selected_df)\n",
    "\n",
    "print(\"Name of features used: {}\".format(elastic_net.feature_names_in_))\n",
    "print(\" \")\n",
    "print(\"Accuracy :\", metrics.accuracy_score(Y_traintest_binary.iloc[:-2], Y_pred_logistic2))\n",
    "print(\" \")\n",
    "print(\"Precision :\", metrics.precision_score(Y_traintest_binary.iloc[:-2],Y_pred_logistic2))\n",
    "print(\" \")\n",
    "print(\"Recall :\", metrics.recall_score(Y_traintest_binary.iloc[:-2],Y_pred_logistic2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831d6912",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_logistic2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234ddd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_traintest_binary.iloc[:-2]"
   ]
  },
  {
   "attachments": {
    "image%20of%20recall%20and%20precision.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "a781009a",
   "metadata": {},
   "source": [
    "![image%20of%20recall%20and%20precision.png](attachment:image%20of%20recall%20and%20precision.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46dc443",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear correlation is expected of a plot between in-sample test and y_pred \n",
    "\n",
    "ax = sns.scatterplot(x=EN_pred_train2, y= Y_traintest.iloc[:-2])\n",
    "ax.set(xlabel='predicted values', ylabel='target values',title=\"Predicted vs Actual Responses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c2c20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#notice that this shape is unconventional. it should have a gradient of +1 and it is showing -1 now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f858a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_logistic2_df = pd.DataFrame(Y_pred_logistic2, index = X_selected_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1333d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773dc77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traintest3 = X.copy()\n",
    "X_traintest3[\"signal\"] = Y_pred_logistic2_df\n",
    "X_traintest3[\"signal\"].iloc[:13] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623b8243",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traintest3[\"signal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df4def3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traintest3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeffd975",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_traintest3[\"strategy_return\"] = X_traintest3[\"signal\"].shift(1) * Y\n",
    "fig,ax = plt.subplots(nrows = 1, ncols = 1, figsize = [16,12])\n",
    "#((X_traintest3[\"strategy_return\"] + 1).cumprod() * capital).plot(ax=ax, label = \"logistic regression\")\n",
    "(X_traintest3[\"strategy_return\"].cumsum().apply(np.exp) * capital).plot(ax=ax, label = \"logistic regression\")\n",
    "#((1+Y).cumprod() * capital).plot(ax=ax, label = \"simple return\")\n",
    "(Y.cumsum().apply(np.exp) * capital).plot(ax=ax, label = \"buy and hold return\")\n",
    "\n",
    "# Add legend\n",
    "ax.legend()\n",
    "\n",
    "# Add title\n",
    "ax.set_title('Long-only Strategy Return vs Benchmark (Y)')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "#capital * (1 + X_traintest3[\"strategy_return\"]).cumprod().plot(figsize=[16,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836d5bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traintest3[\"strategy_return\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a40075",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traintest3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b4984a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15263be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57528983",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLmodel_data=pd.concat([spy,X_traintest3[['signal']]], axis=1)\n",
    "MLmodel_data=MLmodel_data.rename(columns={'signal':'Position'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4363db",
   "metadata": {},
   "outputs": [],
   "source": [
    "Backtest_ML_Strategy=Backtest(MLmodel_data,100000,0)\n",
    "Backtest_ML_Strategy.plot_all_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb235e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Backtest_ML_Strategy.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701f3a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traintest3[\"signal\"].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf580ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40200e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415c0bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumu_ret = X_traintest3[\"strategy_return\"].cumsum().apply(np.exp).iloc[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135203f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traintest3[\"strategy_return\"].cumsum().apply(np.exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e3b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumu_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eccf929",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traintest3[\"strategy_return\"].cumsum().apply(np.exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691b960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traintest3[\"signal\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb15595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what if we can short?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561c04fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = X_traintest3[\"signal\"].copy()\n",
    "short_signal = (signal == 0) * -1 \n",
    "signals = short_signal + signal\n",
    "\n",
    "signals.iloc[:12] = 0\n",
    "signals.value_counts()\n",
    "#X_traintest3[\"signal\"].iloc[:12] = 0\n",
    "#X_traintest3[\"signal\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57d8caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traintest3_copy = X_traintest3.copy()\n",
    "X_traintest3_copy[\"signal\"] = signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1450392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traintest3[\"strategy_return\"] = X_traintest3_copy[\"signal\"].shift(1) * Y\n",
    "\n",
    "fig,ax = plt.subplots(nrows = 1, ncols = 1, figsize = [16,12])\n",
    "\n",
    "(X_traintest3[\"strategy_return\"].cumsum().apply(np.exp) * capital).plot(ax=ax, label = \"logistic regression\")\n",
    "\n",
    "(Y.cumsum().apply(np.exp) * capital).plot(ax=ax, label = \"buy and hold return\")\n",
    "\n",
    "# Add legend\n",
    "ax.legend()\n",
    "\n",
    "# Add title\n",
    "ax.set_title('Long&Short Strategy Return vs Benchmark (Y)')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d74aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traintest3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313c9fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57cea10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fdbad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2997918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cumu_ret_w_short = ((X_traintest3[\"strategy_return\"] + 1).cumprod() * capital).iloc[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf675d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumu_ret_w_short = X_traintest3[\"strategy_return\"].cumsum().apply(np.exp).iloc[-4]\n",
    "X_traintest3[\"strategy_return\"].cumsum().apply(np.exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc42793",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traintest3[\"strategy_return\"].cumsum().apply(np.exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f31eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumu_ret_w_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e7cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "(cumu_ret_w_short - cumu_ret)/ max(cumu_ret_w_short, cumu_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da4f21c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(cumu_ret_w_short - cumu_ret)/ cumu_ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7122b74b",
   "metadata": {},
   "source": [
    "# with optimization of the decision threshold value and best k of feature engineering and alpha in elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2424058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traintest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0279f967",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform X_selected into dataframe\n",
    "\n",
    "X_selected_df = pd.DataFrame(X_selected, columns = X_columns, index = X_traintest.iloc[:-2].index)\n",
    "X_selected_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18249462",
   "metadata": {},
   "source": [
    "# need to perform optimization of k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ded11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "optimize k with mse of linear regression\n",
    "to do that, i need to turn this into a function\n",
    "inputs that i need are : X_traintest, Y_traintest, years_in_data, k_ = \"all\"\n",
    "\n",
    "if k_ != \"all\":\n",
    "    k_ = \"all\"\n",
    "\"\"\"\n",
    "\n",
    "#initiate dictionary to hold data from df.loc[:year]\n",
    "df_dict = {}\n",
    "\n",
    "years_in_data = pd.unique(X_traintest.index.year)\n",
    "\n",
    "def get_feature_engr(X_traintest, Y_traintest, years_in_data, *args):\n",
    "    \n",
    "    k_ = args[0] if args else \"all\"\n",
    "    \n",
    "    for year_ in years_in_data:\n",
    "        mask =\\\n",
    "        (X_traintest\n",
    "         .columns[\n",
    "                     X_traintest\n",
    "                    .apply(lambda col: col.loc[X_traintest.index.year == year_].isna().mean() < 0.3)\n",
    "                 ]\n",
    "        )\n",
    "\n",
    "        X_traintest_to_year = X_traintest.loc[:str(year_), mask].copy()\n",
    "\n",
    "        #Feature scaling, consideration of not removing mean so that the values wont go into negative\n",
    "\n",
    "        X_traintest_to_year =\\\n",
    "        (\n",
    "            X_traintest_to_year\n",
    "            /\n",
    "            X_traintest_to_year.max()\n",
    "        )\n",
    "\n",
    "        Y_traintest_to_year = Y_traintest.loc[:str(year_)]\n",
    "\n",
    "        poly = PolynomialFeatures(degree=3)\n",
    "\n",
    "        #we are shifting the Y values because we need to train the model for a 1 day look ahead\n",
    "        index_ =\\\n",
    "        (Y_traintest_to_year\n",
    "         .shift(-1)\n",
    "         .dropna()\n",
    "         .index \n",
    "        )\n",
    "\n",
    "        X_poly = poly.fit_transform(X_traintest_to_year.loc[index_])  \n",
    "        #(R-squared / (1 - R-squared)) * ((n - unrestricted k - 1) / m), m is total number of unrestricted parameters-1\n",
    "\n",
    "        selector = SelectKBest(score_func=f_regression, k=10) \n",
    "\n",
    "        X_selected = selector.fit_transform(X_poly, Y_traintest.shift(-1).loc[index_]) #Y_traintest_binary\n",
    "\n",
    "        X_columns = selector.get_feature_names_out()\n",
    "\n",
    "        #transform X_selected into dataframe\n",
    "        X_selected_df = pd.DataFrame(X_selected, columns = X_columns, index = index_)\n",
    "\n",
    "        #make sure no missing values\n",
    "        X_selected_df = X_selected_df.ffill()\n",
    "\n",
    "        #columns = X_selected_df.columns \n",
    "\n",
    "        df_dict[year_] = X_selected_df\n",
    "        \n",
    "    return df_dict #X_columns can be retrieved from df_dict[year].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429288da",
   "metadata": {},
   "source": [
    "# analysis: we did feature scaling of z score, use polynomial featuring to overfit and use f-statistics to determine the top variables. Optimization will render this parameter data-centric and it won't require any human input. this leverages on the strength of automation and allowing data to decide the ideal paramter, based on MSE score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0139c760",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = get_feature_engr(X_traintest, Y_traintest, years_in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27a29ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict[2005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f5ef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Specification\n",
    "\n",
    "penalty_ = 0.0\n",
    "\n",
    "def fit_and_predict(df_dict,Y_traintest_series,penalty_):\n",
    "    params_dict = {}\n",
    "    \n",
    "    for year_ in years_in_data:\n",
    "        \n",
    "        X_index = df_dict[year_].index \n",
    "        Y_traintest_series_fraction = Y_traintest_series.loc[X_index]\n",
    "\n",
    "        elastic_net = ElasticNet(alpha=0.01, l1_ratio=penalty_) #alpha is set lower here than above to reduce penalty\n",
    "\n",
    "        elastic_net.fit(df_dict[year_], Y_traintest_series_fraction)\n",
    "        print(\"intercept is {:.3f} and coefficients are {}\".format(elastic_net.intercept_, elastic_net.coef_))\n",
    "\n",
    "        EN_pred_train2 = elastic_net.predict(df_dict[year_])\n",
    "\n",
    "\n",
    "        #continuous predictions are turned into binary signal or 1 and 0 \n",
    "        Y_pred_binary2 = (EN_pred_train2 > 0.0).astype(int)\n",
    "\n",
    "\n",
    "        logreg_sk2 = LogisticRegression(penalty='elasticnet', l1_ratio=penalty_, solver = \"saga\")\n",
    "        logreg_sk2.fit(df_dict[year_], Y_pred_binary2)\n",
    "        print(\"intercept is {:.3f} and coefficients are {}\".format(logreg_sk2.intercept_[0], logreg_sk2.coef_[0]))\n",
    "        \n",
    "\n",
    "        Y_pred_logistic2 = logreg_sk2.predict(df_dict[year_])\n",
    "\n",
    "        Y_pred_logistic2_df = pd.DataFrame(Y_pred_logistic2, index = df_dict[year_].index)\n",
    "\n",
    "        params_dict[f\"EN_pred_{year_}\"] = EN_pred_train2\n",
    "        params_dict[f\"binary_pred_{year_}\"] = Y_pred_binary2\n",
    "        params_dict[f\"logistic_pred_{year_}\"] = Y_pred_logistic2_df\n",
    "\n",
    "        params_dict[f\"Accuracy_{year_}\"] = metrics.accuracy_score(Y_traintest_binary.loc[X_index], Y_pred_logistic2)\n",
    "        params_dict[f\"Precision_{year_}\"] = metrics.precision_score(Y_traintest_binary.loc[X_index],Y_pred_logistic2)\n",
    "        params_dict[f\"Recall_{year_}\"] = metrics.recall_score(Y_traintest_binary.loc[X_index],Y_pred_logistic2)\n",
    "                                                            \n",
    "        print(\"Name of features used: {}\".format(elastic_net.feature_names_in_))\n",
    "        print(\" \")\n",
    "        print(\"Accuracy :\", metrics.accuracy_score(Y_traintest_binary.loc[X_index], Y_pred_logistic2))\n",
    "        print(\" \")\n",
    "        print(\"Precision :\", metrics.precision_score(Y_traintest_binary.loc[X_index],Y_pred_logistic2))\n",
    "        print(\" \")\n",
    "        print(\"Recall :\", metrics.recall_score(Y_traintest_binary.loc[X_index],Y_pred_logistic2))\n",
    "        \n",
    "        #long only    \n",
    "        \n",
    "        X_traintest3 = X.copy()\n",
    "        X_traintest3[\"signal\"] = Y_pred_logistic2_df\n",
    "        X_traintest3[\"signal\"].iloc[:12] = 0\n",
    "\n",
    "        X_traintest3[\"strategy_return\"] = X_traintest3[\"signal\"].shift(1) * Y\n",
    "        fig,ax = plt.subplots(nrows = 1, ncols = 1, figsize = [16,12])\n",
    "\n",
    "        (X_traintest3[\"strategy_return\"].cumsum().apply(np.exp) * capital).plot(ax=ax, label = \"logistic regression\")\n",
    "\n",
    "        (Y.loc[X_index].cumsum().apply(np.exp) * capital).plot(ax=ax, label = \"buy and hold return\")\n",
    "\n",
    "        ax.legend()\n",
    "        ax.set_title('Long-only Strategy Return vs Benchmark (Y)')\n",
    "        plt.show()\n",
    "    \n",
    "    return params_dict, X_traintest3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4606a4bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_traintest2 = Y_traintest.shift(-1).loc[index_] #1 day lookahead\n",
    "\n",
    "params, X_traintest4= fit_and_predict(df_dict,Y_traintest2,penalty_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9885f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traintest4[\"signal\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d7d4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_traintest4[\"strategy_return\"].cumsum().apply(np.exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcd7d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#can turn into a plot function\n",
    "\n",
    "#linear correlation is expected of a plot between in-sample test and y_pred \n",
    "                    #params_dict[]\n",
    "ax = sns.scatterplot(x=EN_pred_train2, y= Y_traintest.iloc[:-2])\n",
    "ax.set(xlabel='predicted values', ylabel='target values',title=\"Predicted vs Actual Responses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b03f41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this can be removed later. this is a long-short strategy \n",
    "\n",
    "penalty_ = 0.0\n",
    "\n",
    "def fit_and_predict_w_short(df_dict,Y_traintest_series,penalty_):\n",
    "    params_dict = {}\n",
    "    \n",
    "    for year_ in years_in_data:\n",
    "        \n",
    "        X_index = df_dict[year_].index \n",
    "        Y_traintest_series_fraction = Y_traintest_series.loc[X_index]\n",
    "\n",
    "        elastic_net = ElasticNet(alpha=0.01, l1_ratio=penalty_)\n",
    "\n",
    "        elastic_net.fit(df_dict[year_], Y_traintest_series_fraction)\n",
    "        print(\"intercept is {:.3f} and coefficients are {}\".format(elastic_net.intercept_, elastic_net.coef_))\n",
    "\n",
    "        EN_pred_train2 = elastic_net.predict(df_dict[year_])\n",
    "\n",
    "\n",
    "        #continuous predictions are turned into binary signal or 1 and 0 \n",
    "        Y_pred_binary2 = (EN_pred_train2 > 0.0).astype(int)\n",
    "\n",
    "\n",
    "        logreg_sk2 = LogisticRegression(penalty='elasticnet', l1_ratio=penalty_, solver = \"saga\")\n",
    "        logreg_sk2.fit(df_dict[year_], Y_pred_binary2)\n",
    "        print(\"intercept is {:.3f} and coefficients are {}\".format(logreg_sk2.intercept_[0], logreg_sk2.coef_[0]))\n",
    "        \n",
    "\n",
    "        Y_pred_logistic2 = logreg_sk2.predict(df_dict[year_])\n",
    "\n",
    "        Y_pred_logistic2_df = pd.DataFrame(Y_pred_logistic2, index = df_dict[year_].index)\n",
    "\n",
    "        params_dict[f\"EN_pred_{year_}\"] = EN_pred_train2\n",
    "        params_dict[f\"binary_pred_{year_}\"] = Y_pred_binary2\n",
    "        params_dict[f\"logistic_pred_{year_}\"] = Y_pred_logistic2_df\n",
    "\n",
    "        params_dict[f\"Accuracy_{year_}\"] = metrics.accuracy_score(Y_traintest_binary.loc[X_index], Y_pred_logistic2)\n",
    "        params_dict[f\"Precision_{year_}\"] = metrics.precision_score(Y_traintest_binary.loc[X_index],Y_pred_logistic2)\n",
    "        params_dict[f\"Recall_{year_}\"] = metrics.recall_score(Y_traintest_binary.loc[X_index],Y_pred_logistic2)\n",
    "                                                            \n",
    "        print(\"Name of features used: {}\".format(elastic_net.feature_names_in_))\n",
    "        print(\" \")\n",
    "        print(\"Accuracy :\", metrics.accuracy_score(Y_traintest_binary.loc[X_index], Y_pred_logistic2))\n",
    "        print(\" \")\n",
    "        print(\"Precision :\", metrics.precision_score(Y_traintest_binary.loc[X_index],Y_pred_logistic2))\n",
    "        print(\" \")\n",
    "        print(\"Recall :\", metrics.recall_score(Y_traintest_binary.loc[X_index],Y_pred_logistic2))\n",
    "        \n",
    "        #long and short\n",
    "        \n",
    "        X_traintest3 = df_dict[year_].copy()\n",
    "        X_traintest3[\"signal\"] = Y_pred_logistic2_df\n",
    "        X_traintest3[\"signal\"].iloc[:13] = 0\n",
    "        \n",
    "        signal = X_traintest3[\"signal\"].copy()\n",
    "        short_signal = (signal == 0) * -1 \n",
    "        signals = short_signal + signal\n",
    "        signals.iloc[:12] = 0\n",
    "        \n",
    "        X_traintest3[\"signal\"] = signals\n",
    "        \n",
    "\n",
    "        X_traintest3[\"strategy_return\"] = X_traintest3[\"signal\"].shift(1) * Y\n",
    "        fig,ax = plt.subplots(nrows = 1, ncols = 1, figsize = [16,12])\n",
    "\n",
    "        (X_traintest3[\"strategy_return\"].cumsum().apply(np.exp) * capital).plot(ax=ax, label = \"logistic regression\")\n",
    "\n",
    "        (Y.loc[X_index].cumsum().apply(np.exp) * capital).plot(ax=ax, label = \"buy and hold return\")\n",
    "\n",
    "        ax.legend()\n",
    "        ax.set_title('Long&Short Strategy Return vs Benchmark (Y)')\n",
    "        plt.show()\n",
    "    \n",
    "    return params_dict, X_traintest3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae40a5e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_traintest2 = Y_traintest.shift(-1).loc[index_] #1 day look-ahead\n",
    "\n",
    "params, X_traintest5= fit_and_predict_w_short(df_dict,Y_traintest2,penalty_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6e873c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(X_traintest5[\"strategy_return\"].cumsum().apply(np.exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c110c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traintest5.signal.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e507e8ac",
   "metadata": {},
   "source": [
    "# CART (decision tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a0eaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Specification\n",
    "\n",
    "penalty_ = 0.0\n",
    "\n",
    "def fit_and_predict_DT(df_dict,Y_traintest_series,penalty_):\n",
    "    params_dict = {}\n",
    "    \n",
    "    for year_ in years_in_data:\n",
    "        \n",
    "        X_index = df_dict[year_].index \n",
    "        Y_traintest_series_fraction = Y_traintest_series.loc[X_index]\n",
    "\n",
    "        DT_model = DecisionTreeRegressor(criterion = \"squared_error\")\n",
    "\n",
    "        DT_model.fit(df_dict[year_], Y_traintest_series_fraction)\n",
    "\n",
    "        DT_pred_train2 = DT_model.predict(df_dict[year_])\n",
    "        \n",
    "        train_result = mean_squared_error(DT_pred_train2, Y_traintest_series_fraction)\n",
    "\n",
    "        DT_pred_train2_df = pd.DataFrame(DT_pred_train2, index = df_dict[year_].index)\n",
    "        \n",
    "        print(\"MSE is {}\".format(train_result))\n",
    "\n",
    "#         params_dict[f\"EN_pred_{year_}\"] = EN_pred_train2\n",
    "#         params_dict[f\"binary_pred_{year_}\"] = Y_pred_binary2\n",
    "#         params_dict[f\"logistic_pred_{year_}\"] = Y_pred_logistic2_df\n",
    "\n",
    "#         params_dict[f\"Accuracy_{year_}\"] = metrics.accuracy_score(Y_traintest_binary.loc[X_index], Y_pred_logistic2)\n",
    "#         params_dict[f\"Precision_{year_}\"] = metrics.precision_score(Y_traintest_binary.loc[X_index],Y_pred_logistic2)\n",
    "#         params_dict[f\"Recall_{year_}\"] = metrics.recall_score(Y_traintest_binary.loc[X_index],Y_pred_logistic2)\n",
    "                                                            \n",
    "#         print(\"Name of features used: {}\".format(elastic_net.feature_names_in_))\n",
    "#         print(\" \")\n",
    "#         print(\"Accuracy :\", metrics.accuracy_score(Y_traintest_binary.loc[X_index], Y_pred_logistic2))\n",
    "#         print(\" \")\n",
    "#         print(\"Precision :\", metrics.precision_score(Y_traintest_binary.loc[X_index],Y_pred_logistic2))\n",
    "#         print(\" \")\n",
    "#         print(\"Recall :\", metrics.recall_score(Y_traintest_binary.loc[X_index],Y_pred_logistic2))\n",
    "\n",
    "        \n",
    "        X_traintest3 = df_dict[year_].copy()\n",
    "        X_traintest3[\"signal\"] = DT_pred_train2_df\n",
    "        X_traintest3[\"signal\"].iloc[:12] = 0\n",
    "        X_traintest3[\"signal\"] = (X_traintest3[\"signal\"] > 0).astype(int)\n",
    "        \n",
    "        X_traintest3[\"strategy_return\"] = X_traintest3[\"signal\"].shift(1) * Y\n",
    "        fig,ax = plt.subplots(nrows = 1, ncols = 1, figsize = [16,12])\n",
    "\n",
    "        (X_traintest3[\"strategy_return\"].cumsum().apply(np.exp) * capital).plot(ax=ax, label = \"CART (classification)\")\n",
    "\n",
    "        (Y.loc[X_index].cumsum().apply(np.exp) * capital).plot(ax=ax, label = \"buy and hold return\")\n",
    "\n",
    "        ax.legend()\n",
    "        ax.set_title('Long-only Strategy Return vs Benchmark (Y)')\n",
    "        plt.show()\n",
    "    \n",
    "    return params_dict, X_traintest3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0480f1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_traintest2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcf98d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_traintest2 = Y_traintest.shift(-1).loc[index_] #1 day look-ahead\n",
    "dummy_df = fit_and_predict_DT(df_dict,Y_traintest2,penalty_)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8d708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df[\"signal\"].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698c3364",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df[\"signal\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2f6aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df[\"strategy_return\"].cumsum().apply(np.exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af27c986",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
